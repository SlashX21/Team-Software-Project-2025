"""
AIå®¢æˆ·ç«¯å·¥å‚æ¨¡å¼
æ”¯æŒOpenAIå’ŒAzure OpenAIçš„ç»Ÿä¸€æ¥å£å’Œè‡ªåŠ¨é™çº§
"""

import asyncio
import logging
from typing import Optional, Any, Dict
from abc import ABC, abstractmethod

from config.settings import get_llm_config, LLMConfig

logger = logging.getLogger(__name__)

class BaseAIClient(ABC):
    """AIå®¢æˆ·ç«¯æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    async def generate_completion(self, prompt: str, config_override: Optional[Dict] = None) -> Any:
        """ç”ŸæˆAIå›å¤"""
        pass
    
    @abstractmethod
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        pass
    
    @abstractmethod
    def get_usage_statistics(self) -> Dict[str, Any]:
        """è·å–ä½¿ç”¨ç»Ÿè®¡"""
        pass

class AIClientFactory:
    """AIå®¢æˆ·ç«¯å·¥å‚ï¼Œæ”¯æŒOpenAIå’ŒAzure OpenAI"""
    
    @staticmethod
    def create_client(provider: str = None) -> BaseAIClient:
        """åˆ›å»ºAIå®¢æˆ·ç«¯"""
        if provider is None:
            # ä»é…ç½®ä¸­è·å–é»˜è®¤provider
            config = get_llm_config()
            provider = getattr(config, 'provider', 'azure')
        
        if provider == "azure":
            from llm_evaluation.azure_openai_client import AzureOpenAIClient
            return AzureOpenAIClient()
        elif provider == "openai":
            from llm_evaluation.openai_client import OpenAIClient
            return OpenAIClient(get_llm_config())
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„AIæœåŠ¡æä¾›å•†: {provider}")
    
    @staticmethod
    def create_with_fallback() -> BaseAIClient:
        """åˆ›å»ºå¸¦é™çº§çš„å®¢æˆ·ç«¯"""
        # ä¼˜å…ˆä½¿ç”¨Azure
        try:
            azure_client = AIClientFactory.create_client("azure")
            logger.info("Azure OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œå°†åœ¨è¿è¡Œæ—¶éªŒè¯è¿æ¥")
            return azure_client
        except Exception as e:
            logger.warning(f"Azure OpenAIåˆå§‹åŒ–å¤±è´¥: {e}")
            
        # é™çº§åˆ°OpenAI
        try:
            openai_client = AIClientFactory.create_client("openai")
            logger.info("é™çº§åˆ°OpenAIå®¢æˆ·ç«¯")
            return openai_client
        except Exception as e:
            logger.error(f"OpenAIåˆå§‹åŒ–ä¹Ÿå¤±è´¥: {e}")
            raise Exception("æ‰€æœ‰AIæœåŠ¡æä¾›å•†éƒ½ä¸å¯ç”¨")
    
    @staticmethod
    def create_resilient_client() -> 'ResilientAIClient':
        """åˆ›å»ºå…·æœ‰è‡ªåŠ¨æ•…éšœæ¢å¤èƒ½åŠ›çš„å®¢æˆ·ç«¯"""
        return ResilientAIClient()

class ResilientAIClient(BaseAIClient):
    """å…·æœ‰æ•…éšœæ¢å¤èƒ½åŠ›çš„AIå®¢æˆ·ç«¯åŒ…è£…å™¨"""
    
    def __init__(self):
        self.primary_client = None
        self.fallback_client = None
        self.last_health_check = 0
        self.health_check_interval = 300  # 5åˆ†é’Ÿ
        self._initialize_clients()
    
    def _initialize_clients(self):
        """åˆå§‹åŒ–å®¢æˆ·ç«¯ - åŒæœåŠ¡æ¨¡å¼ï¼šAzureä¼˜å…ˆï¼ŒOpenAIé™çº§"""
        logger.info("ğŸ”„ åŒæœåŠ¡æ¨¡å¼ï¼šåˆå§‹åŒ–Azure (ä¸»è¦) + OpenAI (é™çº§)")
        
        # ä¸»è¦æœåŠ¡ï¼šAzure OpenAI
        try:
            self.primary_client = AIClientFactory.create_client("azure")
            logger.info("âœ… ä¸»è¦æœåŠ¡: Azure OpenAI åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ Azure OpenAIåˆå§‹åŒ–å¤±è´¥: {e}")
            self.primary_client = None
        
        # é™çº§æœåŠ¡ï¼šOpenAI API
        try:
            self.fallback_client = AIClientFactory.create_client("openai")
            logger.info("âœ… é™çº§æœåŠ¡: OpenAI API åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ OpenAI APIåˆå§‹åŒ–å¤±è´¥: {e}")
            self.fallback_client = None
        
        # æ£€æŸ¥æ˜¯å¦è‡³å°‘æœ‰ä¸€ä¸ªæœåŠ¡å¯ç”¨
        if not self.primary_client and not self.fallback_client:
            raise Exception("âŒ æ‰€æœ‰AIæœåŠ¡éƒ½åˆå§‹åŒ–å¤±è´¥ï¼Œæ— æ³•æä¾›æœåŠ¡")
        
        logger.info(f"ğŸ¯ åŒæœåŠ¡é…ç½®å®Œæˆ: Azure={'å¯ç”¨' if self.primary_client else 'ä¸å¯ç”¨'}, OpenAI={'å¯ç”¨' if self.fallback_client else 'ä¸å¯ç”¨'}")
    
    async def generate_completion(self, prompt: str, config_override: Optional[Dict] = None) -> Any:
        """ç”ŸæˆAIå›å¤ - åŒæœåŠ¡æ¨¡å¼ï¼šAzureä¼˜å…ˆï¼ŒOpenAIé™çº§"""
        
        logger.info(f"ğŸ” [åŒæœåŠ¡] å¼€å§‹AIè°ƒç”¨ï¼Œprompté•¿åº¦: {len(prompt)}")
        
        # ä¼˜å…ˆå°è¯•Azure OpenAI
        if self.primary_client:
            try:
                logger.info("ğŸŸ¡ [Azure] å°è¯•Azure OpenAIä¸»è¦æœåŠ¡...")
                response = await self.primary_client.generate_completion(prompt, config_override)
                
                if hasattr(response, 'success') and response.success:
                    logger.info(f"âœ… [Azure] Azure OpenAIè°ƒç”¨æˆåŠŸï¼")
                    logger.info(f"ğŸ“Š [Azure] å“åº”è¯¦æƒ…: model={getattr(response, 'model', 'unknown')}, tokens={getattr(response.usage, 'total_tokens', 0) if hasattr(response, 'usage') and response.usage else 0}, å¤„ç†æ—¶é—´={getattr(response, 'processing_time_ms', 0)}ms")
                    logger.info(f"ğŸ“ [Azure] å†…å®¹é•¿åº¦: {len(response.content) if hasattr(response, 'content') and response.content else 0} å­—ç¬¦")
                    return response
                else:
                    error_info = getattr(response, 'error', 'Unknown error')
                    logger.warning(f"âš ï¸ [Azure] Azure OpenAIè¿”å›å¤±è´¥: {error_info}")
                    raise Exception(f"Azure OpenAI failed: {error_info}")
                    
            except Exception as e:
                logger.warning(f"ğŸ”„ [Azure] Azure OpenAIå¤±è´¥ï¼Œå‡†å¤‡é™çº§: {e}")
        
        # é™çº§åˆ°OpenAI API
        if self.fallback_client:
            try:
                logger.info("ğŸŸ¡ [OpenAI] é™çº§åˆ°OpenAI API...")
                response = await self.fallback_client.generate_completion(prompt, config_override)
                
                if hasattr(response, 'success') and response.success:
                    logger.info(f"âœ… [OpenAI] OpenAI APIé™çº§æˆåŠŸï¼")
                    logger.info(f"ğŸ“Š [OpenAI] å“åº”è¯¦æƒ…: model={getattr(response, 'model', 'unknown')}, tokens={getattr(response.usage, 'total_tokens', 0) if hasattr(response, 'usage') and response.usage else 0}, å¤„ç†æ—¶é—´={getattr(response, 'processing_time_ms', 0)}ms")
                    logger.info(f"ğŸ“ [OpenAI] å†…å®¹é•¿åº¦: {len(response.content) if hasattr(response, 'content') and response.content else 0} å­—ç¬¦")
                    return response
                else:
                    error_info = getattr(response, 'error', 'Unknown error')
                    logger.error(f"âŒ [OpenAI] OpenAI APIé™çº§ä¹Ÿå¤±è´¥: {error_info}")
                    raise Exception(f"OpenAI API failed: {error_info}")
                    
            except Exception as e:
                logger.error(f"ğŸ’¥ [OpenAI] OpenAI APIå¼‚å¸¸: {e}")
                raise Exception(f"æ‰€æœ‰AIæœåŠ¡éƒ½å¤±è´¥: Azureä¸å¯ç”¨, OpenAI: {str(e)}")
        
        # å¦‚æœä¸¤ä¸ªæœåŠ¡éƒ½ä¸å¯ç”¨
        raise Exception("âŒ æ²¡æœ‰å¯ç”¨çš„AIæœåŠ¡: Azureå’ŒOpenAIéƒ½æœªåˆå§‹åŒ–")
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        current_time = asyncio.get_event_loop().time()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°åˆå§‹åŒ–å®¢æˆ·ç«¯
        if current_time - self.last_health_check > self.health_check_interval:
            await self._periodic_health_check()
            self.last_health_check = current_time
        
        primary_health = {"status": "unavailable"}
        fallback_health = {"status": "unavailable"}
        
        if self.primary_client:
            try:
                primary_health = await self.primary_client.health_check()
            except Exception as e:
                primary_health = {"status": "unhealthy", "error": str(e)}
        
        if self.fallback_client:
            try:
                fallback_health = await self.fallback_client.health_check()
            except Exception as e:
                fallback_health = {"status": "unhealthy", "error": str(e)}
        
        overall_status = "healthy" if (
            primary_health.get("status") == "healthy" or 
            fallback_health.get("status") == "healthy"
        ) else "unhealthy"
        
        return {
            "status": overall_status,
            "primary_client": primary_health,
            "fallback_client": fallback_health,
            "last_health_check": self.last_health_check
        }
    
    async def _periodic_health_check(self):
        """å®šæœŸå¥åº·æ£€æŸ¥å’Œå®¢æˆ·ç«¯é‡æ–°åˆå§‹åŒ–"""
        # å¦‚æœä¸»è¦å®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œå°è¯•é‡æ–°åˆå§‹åŒ–
        if not self.primary_client:
            try:
                self.primary_client = AIClientFactory.create_client("azure")
                logger.info("æˆåŠŸé‡æ–°åˆå§‹åŒ–ä¸»è¦å®¢æˆ·ç«¯")
            except Exception:
                pass
        
        # å¦‚æœå¤‡ç”¨å®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œå°è¯•é‡æ–°åˆå§‹åŒ–
        if not self.fallback_client:
            try:
                self.fallback_client = AIClientFactory.create_client("openai")
                logger.info("æˆåŠŸé‡æ–°åˆå§‹åŒ–å¤‡ç”¨å®¢æˆ·ç«¯")
            except Exception:
                pass
    
    def get_usage_statistics(self) -> Dict[str, Any]:
        """è·å–ä½¿ç”¨ç»Ÿè®¡"""
        stats = {
            "primary_client": {},
            "fallback_client": {},
            "resilient_mode": True
        }
        
        if self.primary_client:
            try:
                stats["primary_client"] = self.primary_client.get_usage_statistics()
            except Exception as e:
                stats["primary_client"] = {"error": str(e)}
        
        if self.fallback_client:
            try:
                stats["fallback_client"] = self.fallback_client.get_usage_statistics()
            except Exception as e:
                stats["fallback_client"] = {"error": str(e)}
        
        return stats
    
    def _get_local_fallback_response(self, prompt: str) -> str:
        """è·å–æœ¬åœ°é™çº§å“åº”"""
        prompt_lower = prompt.lower()
        
        # æ ¹æ®promptå†…å®¹é€‰æ‹©åˆé€‚çš„é™çº§å“åº”
        if "æ¡ç " in prompt_lower or "barcode" in prompt_lower or "æ¨è" in prompt_lower:
            return "åŸºäºå•†å“è¥å…»æ•°æ®ï¼Œæˆ‘ä»¬ä¸ºæ‚¨æ¨èäº†æ›´å¥åº·çš„æ›¿ä»£é€‰æ‹©ã€‚å»ºè®®æŸ¥çœ‹å…·ä½“çš„è¥å…»æˆåˆ†å¯¹æ¯”ä¿¡æ¯ã€‚AIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚"
        elif "å°ç¥¨" in prompt_lower or "receipt" in prompt_lower:
            return "å°ç¥¨åˆ†æåŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ã€‚å»ºè®®æ‰‹åŠ¨æŸ¥çœ‹å„å•†å“çš„è¥å…»ä¿¡æ¯ï¼Œå…³æ³¨ç³–åˆ†ã€è„‚è‚ªå’Œé’ å«é‡ã€‚"
        elif "è¥å…»" in prompt_lower or "nutrition" in prompt_lower:
            return "è¥å…»åˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚å»ºè®®å‚è€ƒå•†å“åŒ…è£…ä¸Šçš„è¥å…»æˆåˆ†è¡¨ï¼Œé€‰æ‹©ä½ç³–ã€ä½è„‚çš„å¥åº·é€‰é¡¹ã€‚"
        else:
            return "AIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚æ‚¨å¯ä»¥æŸ¥çœ‹æ¨èç»“æœçš„åŸºç¡€è¥å…»ä¿¡æ¯ã€‚"

# å…¨å±€å®ä¾‹
_global_resilient_client = None

def get_ai_client() -> BaseAIClient:
    """è·å–å…¨å±€AIå®¢æˆ·ç«¯å®ä¾‹ï¼ˆæ¨èä½¿ç”¨ï¼‰"""
    global _global_resilient_client
    if _global_resilient_client is None:
        _global_resilient_client = ResilientAIClient()
    return _global_resilient_client

def get_simple_ai_client(provider: str = None) -> BaseAIClient:
    """è·å–ç®€å•AIå®¢æˆ·ç«¯ï¼ˆä¸å¸¦æ•…éšœæ¢å¤ï¼‰"""
    return AIClientFactory.create_client(provider)

# ä¾¿æ·å‡½æ•°
async def generate_ai_completion(prompt: str, **kwargs) -> str:
    """ä¾¿æ·çš„AIå®Œæˆç”Ÿæˆå‡½æ•°"""
    client = get_ai_client()
    response = await client.generate_completion(prompt, kwargs)
    
    if hasattr(response, 'success') and response.success:
        return response.content
    elif hasattr(response, 'fallback_used') and response.fallback_used:
        logger.warning("ä½¿ç”¨äº†é™çº§å“åº”")
        return response.content
    else:
        logger.error(f"AIç”Ÿæˆå¤±è´¥: {getattr(response, 'error', 'Unknown error')}")
        return "AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚"

def generate_ai_completion_sync(prompt: str, **kwargs) -> str:
    """åŒæ­¥ç‰ˆæœ¬çš„AIå®Œæˆç”Ÿæˆ"""
    return asyncio.run(generate_ai_completion(prompt, **kwargs))