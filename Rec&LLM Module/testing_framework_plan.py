# æµ‹è¯•æ–‡ä»¶æ„å»ºå¼€å‘æ¡£æ¡ˆ - Grocery Guardian

## ğŸ¯ æµ‹è¯•ç›®æ ‡

æ„å»ºå…¨é¢çš„æµ‹è¯•æ¡†æ¶ï¼ŒéªŒè¯æ¨èç®—æ³•çš„å‡†ç¡®æ€§ã€LLMè¯„ä¼°çš„è´¨é‡ã€ç³»ç»Ÿçš„é²æ£’æ€§å’Œæ€§èƒ½æŒ‡æ ‡ï¼Œç¡®ä¿demoæ¨¡å—è¾¾åˆ°ç”Ÿäº§çº§è´¨é‡æ ‡å‡†ã€‚

## ğŸ—ï¸ æµ‹è¯•æ¡†æ¶æ¶æ„ï¼ˆJavaå…¼å®¹æ€§é‡ç‚¹ï¼‰

### æµ‹è¯•å±‚æ¬¡è®¾è®¡
```
grocery_guardian_demo/tests/
â”œâ”€â”€ unit_tests/                    # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ test_database/             # æ•°æ®åº“é€‚é…å™¨æµ‹è¯•
â”‚   â”‚   â”œâ”€â”€ test_sqlite_adapter.py
â”‚   â”‚   â”œâ”€â”€ test_sqlserver_adapter.py
â”‚   â”‚   â””â”€â”€ test_adapter_factory.py
â”‚   â”œâ”€â”€ test_filters/              # è¿‡æ»¤å™¨ç®—æ³•æµ‹è¯•
â”‚   â”œâ”€â”€ test_recommendation/       # æ¨èç®—æ³•æµ‹è¯•
â”‚   â””â”€â”€ test_llm/                  # LLMé›†æˆæµ‹è¯•
â”œâ”€â”€ integration_tests/             # é›†æˆæµ‹è¯•
â”‚   â”œâ”€â”€ test_recommendation_flow/  # å®Œæ•´æ¨èæµç¨‹æµ‹è¯•
â”‚   â”œâ”€â”€ test_api_endpoints/        # APIæ¥å£æµ‹è¯•
â”‚   â””â”€â”€ test_java_compatibility/   # Javaå…¼å®¹æ€§æµ‹è¯• â­
â”œâ”€â”€ compatibility_tests/           # å…¼å®¹æ€§ä¸“é¡¹æµ‹è¯• â­
â”‚   â”œâ”€â”€ test_dto_serialization/    # DTOåºåˆ—åŒ–æµ‹è¯•
â”‚   â”œâ”€â”€ test_api_contracts/        # APIå¥‘çº¦æµ‹è¯•
â”‚   â””â”€â”€ test_database_migration/   # æ•°æ®åº“è¿ç§»æµ‹è¯•
â”œâ”€â”€ performance_tests/             # æ€§èƒ½æµ‹è¯•
â”‚   â”œâ”€â”€ test_response_time/        # å“åº”æ—¶é—´æµ‹è¯•
â”‚   â””â”€â”€ test_load_capacity/        # è´Ÿè½½èƒ½åŠ›æµ‹è¯•
â”œâ”€â”€ scenario_tests/                # åœºæ™¯æµ‹è¯•
â”‚   â”œâ”€â”€ barcode_scenarios/         # æ¡å½¢ç æ‰«æåœºæ™¯
â”‚   â””â”€â”€ receipt_scenarios/         # å°ç¥¨åˆ†æåœºæ™¯
â”œâ”€â”€ test_data/                     # æµ‹è¯•æ•°æ®
â”‚   â”œâ”€â”€ products/                  # å•†å“æµ‹è¯•æ•°æ®
â”‚   â”œâ”€â”€ users/                     # ç”¨æˆ·æµ‹è¯•æ•°æ®
â”‚   â”œâ”€â”€ scenarios/                 # æµ‹è¯•åœºæ™¯é…ç½®
â”‚   â”œâ”€â”€ java_dto_samples/          # Java DTOæ ·æœ¬æ•°æ® â­
â”‚   â””â”€â”€ expected_outputs/          # é¢„æœŸè¾“å‡ºåŸºå‡†
â””â”€â”€ test_utilities/                # æµ‹è¯•å·¥å…·
    â”œâ”€â”€ data_generators.py         # æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨
    â”œâ”€â”€ validators.py              # ç»“æœéªŒè¯å™¨
    â”œâ”€â”€ mock_services.py           # æ¨¡æ‹ŸæœåŠ¡
    â””â”€â”€ java_compatibility_utils.py # Javaå…¼å®¹æ€§å·¥å…· â­
```

## ğŸ”— Javaå…¼å®¹æ€§æµ‹è¯•æ¡†æ¶ï¼ˆé‡ç‚¹ï¼‰

### 1. æ•°æ®åº“é€‚é…å™¨å…¼å®¹æ€§æµ‹è¯•
```python
class DatabaseAdapterCompatibilityTest:
    """æ•°æ®åº“é€‚é…å™¨å…¼å®¹æ€§æµ‹è¯•"""
    
    def test_sqlite_to_sqlserver_schema_compatibility(self):
        """æµ‹è¯•SQLiteåˆ°SQL Serverçš„schemaå…¼å®¹æ€§"""
        # éªŒè¯æ•°æ®ç±»å‹æ˜ å°„æ­£ç¡®æ€§
        # æµ‹è¯•å¤–é”®çº¦æŸä¸€è‡´æ€§
        # éªŒè¯ç´¢å¼•è½¬æ¢å‡†ç¡®æ€§
        
        type_mappings = {
            "NVARCHAR(20)": "barcodeå­—æ®µ",
            "NVARCHAR(200)": "nameå­—æ®µ", 
            "NVARCHAR(MAX)": "ingredientså­—æ®µ",
            "FLOAT": "è¥å…»æˆåˆ†å­—æ®µ",
            "INT IDENTITY(1,1)": "è‡ªå¢ä¸»é”®",
            "BIT": "å¸ƒå°”å­—æ®µ",
            "DATETIME2": "æ—¶é—´æˆ³å­—æ®µ"
        }
        
        for sql_server_type, description in type_mappings.items():
            # éªŒè¯æ¯ç§æ•°æ®ç±»å‹çš„å…¼å®¹æ€§
            pass
    
    def test_adapter_factory_creation(self):
        """æµ‹è¯•é€‚é…å™¨å·¥å‚çš„åˆ›å»ºé€»è¾‘"""
        # æµ‹è¯•SQLiteé€‚é…å™¨åˆ›å»º
        sqlite_config = {"type": "sqlite", "connection_string": "test.db"}
        sqlite_adapter = DatabaseAdapterFactory.create_adapter("sqlite", sqlite_config)
        assert isinstance(sqlite_adapter, SQLiteAdapter)
        
        # æµ‹è¯•SQL Serveré€‚é…å™¨åˆ›å»º
        sqlserver_config = {"type": "sqlserver", "connection_string": "test_connection"}
        sqlserver_adapter = DatabaseAdapterFactory.create_adapter("sqlserver", sqlserver_config)
        assert isinstance(sqlserver_adapter, SqlServerAdapter)
    
    def test_query_result_consistency(self):
        """æµ‹è¯•ä¸åŒé€‚é…å™¨æŸ¥è¯¢ç»“æœçš„ä¸€è‡´æ€§"""
        # ä½¿ç”¨ç›¸åŒçš„æµ‹è¯•æ•°æ®ï¼ŒéªŒè¯SQLiteå’ŒSQL Serverè¿”å›ç»“æœä¸€è‡´
        test_barcode = "1234567890123"
        
        sqlite_result = self.sqlite_adapter.get_product_by_barcode(test_barcode)
        sqlserver_result = self.sqlserver_adapter.get_product_by_barcode(test_barcode)
        
        # éªŒè¯å…³é”®å­—æ®µä¸€è‡´æ€§
        assert sqlite_result["barcode"] == sqlserver_result["barcode"]
        assert sqlite_result["name"] == sqlserver_result["name"]
        # ... å…¶ä»–å­—æ®µéªŒè¯

class ApiContractTest:
    """APIå¥‘çº¦æµ‹è¯•ï¼Œç¡®ä¿ä¸Javaåç«¯å…¼å®¹"""
    
    def test_request_dto_compatibility(self):
        """æµ‹è¯•è¯·æ±‚DTOä¸Javaå®ä½“çš„å…¼å®¹æ€§"""
        # Javaé£æ ¼çš„è¯·æ±‚æ•°æ®
        java_style_request = {
            "scanType": "barcode",  # Javaé©¼å³°å‘½å
            "userId": 1,
            "productBarcode": "1234567890123",
            "scanContext": {
                "location": "Tesco",
                "timestamp": "2025-06-12T14:30:00Z"  # ISOæ ¼å¼
            }
        }
        
        # éªŒè¯Python APIèƒ½æ­£ç¡®è§£æJavaé£æ ¼è¯·æ±‚
        parsed_request = BarcodeRecommendationRequest(**java_style_request)
        assert parsed_request.scan_type == "barcode"
        assert parsed_request.user_id == 1
    
    def test_response_dto_compatibility(self):
        """æµ‹è¯•å“åº”DTOä¸Javaå®ä½“çš„å…¼å®¹æ€§"""
        # ç”Ÿæˆæ¨èå“åº”
        response = self.recommendation_engine.recommend_alternatives(test_request)
        
        # éªŒè¯å“åº”æ ¼å¼ç¬¦åˆJavaæœŸæœ›
        assert "recommendationId" in response.dict(by_alias=True)
        assert "scanType" in response.dict(by_alias=True)
        assert "userProfileSummary" in response.dict(by_alias=True)
        
        # éªŒè¯æ—¥æœŸæ ¼å¼
        timestamp = response.processing_metadata["timestamp"]
        assert re.match(r'\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}', timestamp)
    
    def test_error_response_spring_boot_compatibility(self):
        """æµ‹è¯•é”™è¯¯å“åº”ä¸Spring Bootå¼‚å¸¸æ ¼å¼å…¼å®¹"""
        # æ¨¡æ‹Ÿé”™è¯¯æƒ…å†µ
        invalid_request = {"scanType": "invalid"}
        
        response = self.api_client.post("/recommend", json=invalid_request)
        error_response = response.json()
        
        # éªŒè¯Spring Bootæ ‡å‡†é”™è¯¯æ ¼å¼
        assert "success" in error_response
        assert "message" in error_response
        assert "error" in error_response
        assert "timestamp" in error_response
        assert error_response["success"] is False

class DataSerializationTest:
    """æ•°æ®åºåˆ—åŒ–å…¼å®¹æ€§æµ‹è¯•"""
    
    def test_json_serialization_java_compatibility(self):
        """æµ‹è¯•JSONåºåˆ—åŒ–ä¸Java Jacksonå…¼å®¹"""
        # åˆ›å»ºæµ‹è¯•å¯¹è±¡
        product = ProductDTO(
            barcode="1234567890123",
            name="Test Product",
            brand="Test Brand",
            category="Food",
            energyKcalPer100g=250.5
        )
        
        # åºåˆ—åŒ–ä¸ºJSON
        json_data = product.json(by_alias=True)
        parsed_data = json.loads(json_data)
        
        # éªŒè¯JavaæœŸæœ›çš„å­—æ®µå
        assert "energyKcalPer100g" in parsed_data  # é©¼å³°å‘½å
        assert "energy_kcal_100g" not in parsed_data  # ä¸åŒ…å«ä¸‹åˆ’çº¿å‘½å
    
    def test_datetime_serialization_compatibility(self):
        """æµ‹è¯•æ—¥æœŸæ—¶é—´åºåˆ—åŒ–ä¸Java LocalDateTimeå…¼å®¹"""
        from datetime import datetime
        
        test_datetime = datetime.now()
        iso_format = test_datetime.isoformat()
        
        # éªŒè¯ISOæ ¼å¼ç¬¦åˆJava LocalDateTimeè§£æè¦æ±‚
        assert "T" in iso_format
        assert len(iso_format.split("T")) == 2
    
    def test_null_value_handling(self):
        """æµ‹è¯•ç©ºå€¼å¤„ç†ä¸Java Optionalå…¼å®¹"""
        # åˆ›å»ºåŒ…å«ç©ºå€¼çš„å¯¹è±¡
        product = ProductDTO(
            barcode="1234567890123",
            name="Test Product",
            brand=None,  # ç©ºå€¼
            category="Food"
        )
        
        json_data = json.loads(product.json(by_alias=True))
        
### 2. æ•°æ®åº“è¿ç§»æµ‹è¯•
```python
class DatabaseMigrationTest:
    """æ•°æ®åº“è¿ç§»å…¼å®¹æ€§æµ‹è¯•"""
    
    def test_schema_migration_accuracy(self):
        """æµ‹è¯•schemaè¿ç§»çš„å‡†ç¡®æ€§"""
        # æ¯”è¾ƒSQLiteå’ŒSQL Serverçš„è¡¨ç»“æ„
        sqlite_schema = self.get_sqlite_schema()
        sqlserver_schema = self.get_expected_sqlserver_schema()
        
        # éªŒè¯è¡¨æ•°é‡ä¸€è‡´
        assert len(sqlite_schema.tables) == len(sqlserver_schema.tables)
        
        # éªŒè¯å…³é”®è¡¨çš„å­—æ®µæ˜ å°„
        for table_name in ["PRODUCT", "USER", "ALLERGEN"]:
            sqlite_table = sqlite_schema.tables[table_name]
            sqlserver_table = sqlserver_schema.tables[table_name]
            
            # éªŒè¯å­—æ®µæ•°é‡
            assert len(sqlite_table.columns) == len(sqlserver_table.columns)
            
            # éªŒè¯æ•°æ®ç±»å‹æ˜ å°„
            for col_name in sqlite_table.columns:
                sqlite_type = sqlite_table.columns[col_name].type
                sqlserver_type = sqlserver_table.columns[col_name].type
                assert self.is_compatible_type(sqlite_type, sqlserver_type)
    
    def test_data_migration_integrity(self):
        """æµ‹è¯•æ•°æ®è¿ç§»çš„å®Œæ•´æ€§"""
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_products = self.create_test_products(count=100)
        test_users = self.create_test_users(count=10)
        
        # åœ¨SQLiteä¸­æ’å…¥æ•°æ®
        self.sqlite_adapter.bulk_insert_products(test_products)
        self.sqlite_adapter.bulk_insert_users(test_users)
        
        # æ¨¡æ‹Ÿè¿ç§»è¿‡ç¨‹
        migrated_data = self.simulate_migration()
        
        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        assert len(migrated_data["products"]) == len(test_products)
        assert len(migrated_data["users"]) == len(test_users)
        
        # éªŒè¯å…³é”®å­—æ®µçš„æ•°æ®ä¸€è‡´æ€§
        for original, migrated in zip(test_products, migrated_data["products"]):
            assert original["barcode"] == migrated["barcode"]
            assert original["name"] == migrated["name"]
            # éªŒè¯è¥å…»æ•°æ®ç²¾åº¦ä¿æŒ
            assert abs(original["energy_kcal_100g"] - migrated["energy_kcal_100g"]) < 0.01
    
    def test_constraint_migration(self):
        """æµ‹è¯•çº¦æŸè¿ç§»çš„æ­£ç¡®æ€§"""
        # éªŒè¯ä¸»é”®çº¦æŸ
        # éªŒè¯å¤–é”®çº¦æŸ
        # éªŒè¯å”¯ä¸€æ€§çº¦æŸ
        # éªŒè¯æ£€æŸ¥çº¦æŸ
        pass

## ğŸ“‹ æ ¸å¿ƒæµ‹è¯•åœºæ™¯è®¾è®¡ï¼ˆä¿æŒåŸæœ‰è®¾è®¡ï¼‰

### 1. æ¡å½¢ç æ‰«ææµ‹è¯•åœºæ™¯
```

#### åœºæ™¯1: å‡è„‚ç”¨æˆ·æ‰«æé«˜ç³–é¥®æ–™
```json
{
  "scenario_id": "barcode_001_weight_loss_sugary_drink",
  "description": "å‡è„‚ç”¨æˆ·æ‰«æé«˜ç³–å¯ä¹ï¼ŒæœŸæœ›æ¨èæ— ç³–æ›¿ä»£å“",
  "test_data": {
    "user_profile": {
      "user_id": 1,
      "username": "weight_loss_user",
      "nutrition_goal": "lose_weight",
      "daily_calories_target": 1800,
      "allergens": ["caffeine_sensitive"]
    },
    "scanned_product": {
      "barcode": "5449000000996",
      "name": "Coca-Cola Classic",
      "brand": "Coca-Cola",
      "category": "Beverages",
      "energy_kcal_100g": 180,
      "sugars_100g": 39.0,
      "fat_100g": 0.0,
      "proteins_100g": 0.0
    }
  },
  "expected_outcomes": {
    "recommendation_count": 3,
    "sugar_reduction_min": 80,  # è‡³å°‘å‡å°‘80%ç³–åˆ†
    "calorie_reduction_min": 70, # è‡³å°‘å‡å°‘70%çƒ­é‡
    "allergen_safety": true,
    "category_constraint": "Beverages",
    "llm_analysis_keywords": ["æ— ç³–", "å‡è„‚", "å¥åº·æ›¿ä»£", "å¡è·¯é‡Œæ§åˆ¶"]
  }
}
```

#### åœºæ™¯2: å¢è‚Œç”¨æˆ·æ‰«ææ™®é€šé¢åŒ…
```json
{
  "scenario_id": "barcode_002_muscle_gain_bread",
  "description": "å¢è‚Œç”¨æˆ·æ‰«æç™½é¢åŒ…ï¼ŒæœŸæœ›æ¨èé«˜è›‹ç™½é¢åŒ…",
  "test_data": {
    "user_profile": {
      "user_id": 2,
      "username": "fitness_enthusiast",
      "nutrition_goal": "gain_muscle",
      "daily_protein_target": 150,
      "allergens": ["gluten_free"]
    },
    "scanned_product": {
      "barcode": "7622210951717",
      "name": "White Sliced Bread",
      "brand": "Brennans",
      "category": "Food",
      "energy_kcal_100g": 265,
      "proteins_100g": 8.5,
      "carbohydrates_100g": 49.0,
      "fat_100g": 3.2
    }
  },
  "expected_outcomes": {
    "recommendation_count": 4,
    "protein_increase_min": 50,  # è‡³å°‘å¢åŠ 50%è›‹ç™½è´¨
    "gluten_free": true,
    "category_constraint": "Food",
    "llm_analysis_keywords": ["é«˜è›‹ç™½", "å¢è‚Œ", "æ— éº¸è´¨", "è¥å…»å¢å¼º"]
  }
}
```

#### åœºæ™¯3: è¿‡æ•ç”¨æˆ·æ‰«æå«è¿‡æ•åŸå•†å“
```json
{
  "scenario_id": "barcode_003_allergen_conflict",
  "description": "åšæœè¿‡æ•ç”¨æˆ·æ‰«æå«åšæœå•†å“ï¼ŒæœŸæœ›å®‰å…¨æ›¿ä»£å“",
  "test_data": {
    "user_profile": {
      "user_id": 3,
      "username": "allergen_sensitive_user",
      "nutrition_goal": "maintain",
      "allergens": ["nuts", "almonds", "walnuts"]
    },
    "scanned_product": {
      "barcode": "20045325",
      "name": "Mixed Nuts Snack",
      "brand": "Planters",
      "category": "Snacks",
      "allergens": "Contains: Nuts, Almonds, Walnuts, May contain: Peanuts"
    }
  },
  "expected_outcomes": {
    "recommendation_count": 5,
    "allergen_safety": true,
    "nuts_free": true,
    "category_constraint": "Snacks",
    "llm_analysis_keywords": ["æ— åšæœ", "å®‰å…¨æ›¿ä»£", "è¿‡æ•å‹å¥½", "è¥å…»ç›¸ä¼¼"]
  }
}
```

### 2. å°ç¥¨åˆ†ææµ‹è¯•åœºæ™¯

#### åœºæ™¯1: ä¸å¥åº·è´­ç‰©å°ç¥¨åˆ†æ
```json
{
  "scenario_id": "receipt_001_unhealthy_pattern",
  "description": "åˆ†æé«˜ç³–é«˜è„‚è´­ç‰©æ¨¡å¼ï¼Œæä¾›å¥åº·æ”¹è¿›å»ºè®®",
  "test_data": {
    "user_profile": {
      "user_id": 1,
      "nutrition_goal": "lose_weight",
      "daily_calories_target": 1800
    },
    "purchased_items": [
      {
        "barcode": "5449000000996",
        "item_name": "Coca-Cola Classic 500ml",
        "quantity": 6,
        "unit_price": 1.25,
        "category": "Beverages"
      },
      {
        "barcode": "7622210951717",
        "item_name": "Chocolate Chip Cookies",
        "quantity": 2,
        "unit_price": 3.99,
        "category": "Snacks"
      },
      {
        "barcode": "40822527",
        "item_name": "Frozen Pizza",
        "quantity": 3,
        "unit_price": 4.50,
        "category": "Food"
      }
    ],
    "receipt_context": {
      "store": "Tesco",
      "purchase_date": "2025-06-12",
      "total_amount": 29.47
    }
  },
  "expected_outcomes": {
    "overall_health_score": "éœ€è¦æ”¹è¿›",
    "calorie_excess_warning": true,
    "sugar_content_alert": true,
    "replacement_suggestions_count": 6,
    "llm_analysis_keywords": ["é«˜ç³–è­¦å‘Š", "å¡è·¯é‡Œè¶…æ ‡", "å¥åº·æ›¿ä»£", "è¥å…»å¹³è¡¡"]
  }
}
```

#### åœºæ™¯2: å‡è¡¡è´­ç‰©å°ç¥¨åˆ†æ
```json
{
  "scenario_id": "receipt_002_balanced_pattern",
  "description": "åˆ†æè¥å…»å‡è¡¡çš„è´­ç‰©æ¨¡å¼ï¼Œæä¾›ç»´æŒå»ºè®®",
  "test_data": {
    "user_profile": {
      "user_id": 3,
      "nutrition_goal": "maintain"
    },
    "purchased_items": [
      {
        "barcode": "5391518377133",
        "item_name": "Organic Chicken Breast",
        "quantity": 1,
        "unit_price": 8.99,
        "category": "Food"
      },
      {
        "barcode": "5391520001342",
        "item_name": "Brown Rice",
        "quantity": 1,
        "unit_price": 2.49,
        "category": "Food"
      },
      {
        "barcode": "5391518334527",
        "item_name": "Mixed Vegetables",
        "quantity": 2,
        "unit_price": 1.99,
        "category": "Food"
      }
    ]
  },
  "expected_outcomes": {
    "overall_health_score": "ä¼˜ç§€",
    "nutrition_balance_score": ">85%",
    "protein_adequacy": true,
    "vegetable_variety": "å……è¶³",
    "llm_analysis_keywords": ["è¥å…»å‡è¡¡", "å¥åº·é€‰æ‹©", "ç»§ç»­ä¿æŒ", "å¤šæ ·åŒ–"]
  }
}
```

## ğŸ§ª æµ‹è¯•æ•°æ®ç”Ÿæˆç­–ç•¥

### æµ‹è¯•å•†å“æ•°æ®åº“æ„å»º
```python
class TestProductGenerator:
    def generate_representative_products(self) -> List[dict]:
        """ç”Ÿæˆä»£è¡¨æ€§å•†å“æµ‹è¯•æ•°æ®"""
        categories = {
            'Food': ['é«˜è›‹ç™½é£Ÿå“', 'ä½è„‚é£Ÿå“', 'é«˜çº¤ç»´é£Ÿå“', 'åŠ å·¥é£Ÿå“'],
            'Beverages': ['é«˜ç³–é¥®æ–™', 'æ— ç³–é¥®æ–™', 'åŠŸèƒ½é¥®æ–™', 'å¤©ç„¶æœæ±'],
            'Snacks': ['å¥åº·é›¶é£Ÿ', 'é«˜ç³–é›¶é£Ÿ', 'åšæœç±»', 'è–¯ç‰‡ç±»'],
            'Health & Supplements': ['è›‹ç™½ç²‰', 'ç»´ç”Ÿç´ ', 'æœ‰æœºé£Ÿå“'],
            'Condiments & Others': ['è°ƒæ–™', 'æ²¹ç±»', 'é¦™æ–™']
        }
        
        for category, subcategories in categories.items():
            for subcategory in subcategories:
                # ä¸ºæ¯ä¸ªå­ç±»åˆ«ç”Ÿæˆ5-10ä¸ªä»£è¡¨æ€§å•†å“
                # è¦†ç›–ä¸åŒçš„è¥å…»ç‰¹å¾å’Œè¿‡æ•åŸç»„åˆ
                pass
    
    def create_edge_case_products(self) -> List[dict]:
        """åˆ›å»ºè¾¹ç•Œæƒ…å†µæµ‹è¯•å•†å“"""
        edge_cases = [
            "è¥å…»ä¿¡æ¯ç¼ºå¤±å•†å“",
            "æé«˜/æä½è¥å…»å€¼å•†å“",
            "å¤šç§è¿‡æ•åŸç»„åˆå•†å“",
            "å¼‚å¸¸ä»·æ ¼å•†å“",
            "æ–°å“ç±»å•†å“"
        ]
        
    def generate_allergen_test_matrix(self) -> List[dict]:
        """ç”Ÿæˆè¿‡æ•åŸæµ‹è¯•çŸ©é˜µ"""
        # åˆ›å»ºåŒ…å«ä¸åŒè¿‡æ•åŸç»„åˆçš„å•†å“
        # æµ‹è¯•è¿‡æ•åŸæ£€æµ‹çš„å‡†ç¡®æ€§å’Œè¦†ç›–åº¦
```

### æµ‹è¯•ç”¨æˆ·ç”»åƒç”Ÿæˆ
```python
class TestUserGenerator:
    def create_diverse_user_profiles(self) -> List[dict]:
        """åˆ›å»ºå¤šæ ·åŒ–çš„æµ‹è¯•ç”¨æˆ·ç”»åƒ"""
        user_templates = [
            {
                "category": "å‡è„‚ç”¨æˆ·",
                "variations": ["è½»åº¦è¶…é‡", "ä¸­åº¦è‚¥èƒ–", "äº§åæ¢å¤", "è€å¹´å‡è„‚"],
                "allergen_combinations": [[], ["lactose"], ["gluten", "nuts"], ["multiple_severe"]]
            },
            {
                "category": "å¢è‚Œç”¨æˆ·", 
                "variations": ["ç˜¦ä½“è´¨å¢é‡", "å¥èº«çˆ±å¥½è€…", "ä¸“ä¸šè¿åŠ¨å‘˜", "åº·å¤æœŸå¢è‚Œ"],
                "allergen_combinations": [[], ["dairy"], ["soy"], ["comprehensive_restrictions"]]
            },
            {
                "category": "ç»´æŒç”¨æˆ·",
                "variations": ["å¥åº·æˆå¹´äºº", "è½»åº¦æ´»åŠ¨", "åŠå…¬å®¤å·¥ä½œè€…", "é€€ä¼‘äººå‘˜"],
                "allergen_combinations": [[], ["environmental"], ["food_additives"], ["age_related"]]
            }
        ]
        
    def generate_purchase_history_patterns(self, user_profile: dict) -> List[dict]:
        """ä¸ºæµ‹è¯•ç”¨æˆ·ç”Ÿæˆé€¼çœŸçš„è´­ä¹°å†å²"""
        # åŸºäºç”¨æˆ·ç›®æ ‡ç”Ÿæˆç¬¦åˆé€»è¾‘çš„è´­ä¹°æ¨¡å¼
        # åŒ…å«è¿›æ­¥è½¨è¿¹å’Œå¶å°”çš„"ä½œå¼Š"è´­ä¹°
        # å­£èŠ‚æ€§å˜åŒ–å’Œç‰¹æ®Šäº‹ä»¶å½±å“
```

## ğŸ” æµ‹è¯•éªŒè¯æ¡†æ¶

### æ¨èè´¨é‡éªŒè¯å™¨
```python
class RecommendationValidator:
    def validate_allergen_safety(self, recommendations: List[dict], 
                                user_allergens: List[str]) -> bool:
        """éªŒè¯è¿‡æ•åŸå®‰å…¨æ€§ - 100%å‡†ç¡®ç‡è¦æ±‚"""
        for rec in recommendations:
            product_allergens = self.extract_product_allergens(rec['barcode'])
            for allergen in user_allergens:
                if allergen in product_allergens:
                    return False
        return True
    
    def validate_nutrition_improvement(self, original: dict, 
                                     recommendations: List[dict], 
                                     user_goal: str) -> dict:
        """éªŒè¯è¥å…»æ”¹å–„åº¦"""
        improvement_metrics = {
            'lose_weight': ['calories_reduction', 'fat_reduction', 'sugar_reduction'],
            'gain_muscle': ['protein_increase', 'calorie_adequacy', 'carb_balance'],
            'maintain': ['nutrition_balance', 'variety_score', 'natural_score']
        }
        
        results = {}
        for metric in improvement_metrics[user_goal]:
            results[metric] = self.calculate_improvement_metric(
                original, recommendations, metric)
        return results
    
    def validate_category_constraints(self, original_category: str, 
                                    recommendations: List[dict],
                                    scan_type: str) -> bool:
        """éªŒè¯åˆ†ç±»çº¦æŸ"""
        if scan_type == 'barcode':
            # æ¡å½¢ç æ‰«æå¿…é¡»åŒåˆ†ç±»
            return all(rec['category'] == original_category for rec in recommendations)
        else:
            # å°ç¥¨åˆ†æå¯è·¨åˆ†ç±»ï¼Œä½†éœ€åˆç†
            return True
```

### LLMè´¨é‡éªŒè¯å™¨  
```python
class LLMQualityValidator:
    def validate_analysis_accuracy(self, llm_response: str, 
                                  nutrition_data: dict) -> dict:
        """éªŒè¯LLMåˆ†æçš„æ•°æ®å‡†ç¡®æ€§"""
        extracted_numbers = self.extract_numbers_from_text(llm_response)
        nutrition_numbers = self.flatten_nutrition_data(nutrition_data)
        
        accuracy_score = self.calculate_number_accuracy(
            extracted_numbers, nutrition_numbers)
        
        return {
            'data_accuracy': accuracy_score,
            'calculation_errors': self.find_calculation_errors(llm_response),
            'factual_consistency': self.check_factual_consistency(llm_response)
        }
    
    def validate_personalization_quality(self, llm_response: str,
                                       user_profile: dict) -> dict:
        """éªŒè¯ä¸ªæ€§åŒ–ç¨‹åº¦"""
        personalization_indicators = {
            'age_consideration': self.check_age_references(llm_response, user_profile['age']),
            'goal_alignment': self.check_goal_mentions(llm_response, user_profile['nutrition_goal']),
            'allergen_awareness': self.check_allergen_mentions(llm_response, user_profile['allergens']),
            'activity_consideration': self.check_activity_references(llm_response, user_profile['activity_level'])
        }
        
        return personalization_indicators
    
    def validate_safety_and_ethics(self, llm_response: str) -> dict:
        """éªŒè¯å®‰å…¨æ€§å’Œä¼¦ç†è€ƒè™‘"""
        safety_checks = {
            'medical_disclaimers': self.check_medical_disclaimers(llm_response),
            'absolute_claims_avoided': self.check_absolute_medical_claims(llm_response),
            'balanced_language': self.check_balanced_language(llm_response),
            'no_harmful_advice': self.check_harmful_advice(llm_response)
        }
        
        return safety_checks
```

## âš¡ æ€§èƒ½æµ‹è¯•æ¡†æ¶

### å“åº”æ—¶é—´æµ‹è¯•
```python
class PerformanceTestSuite:
    def test_recommendation_response_time(self):
        """æµ‹è¯•æ¨èå“åº”æ—¶é—´"""
        test_cases = [
            {"complexity": "simple", "target_time": 1.0},  # ç®€å•æ¨è<1ç§’
            {"complexity": "medium", "target_time": 1.5},  # ä¸­ç­‰å¤æ‚åº¦<1.5ç§’
            {"complexity": "complex", "target_time": 2.0}  # å¤æ‚åˆ†æ<2ç§’
        ]
        
        for case in test_cases:
            start_time = time.time()
            result = self.execute_recommendation_request(case)
            end_time = time.time()
            
            response_time = end_time - start_time
            assert response_time < case["target_time"], \
                f"Response time {response_time:.2f}s exceeds target {case['target_time']}s"
    
    def test_database_query_performance(self):
        """æµ‹è¯•æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½"""
        query_benchmarks = {
            'single_product_lookup': 0.05,     # 50ms
            'category_filter': 0.1,            # 100ms
            'allergen_check': 0.03,            # 30ms
            'user_profile_load': 0.02,         # 20ms
            'purchase_history': 0.15           # 150ms
        }
        
        for query_type, target_time in query_benchmarks.items():
            actual_time = self.benchmark_query(query_type)
            assert actual_time < target_time, \
                f"Query {query_type} took {actual_time:.3f}s, target: {target_time:.3f}s"
    
    def test_llm_api_performance(self):
        """æµ‹è¯•LLM APIè°ƒç”¨æ€§èƒ½"""
        # æµ‹è¯•ä¸åŒprompté•¿åº¦ä¸‹çš„å“åº”æ—¶é—´
        # æµ‹è¯•å¹¶å‘è°ƒç”¨å¤„ç†èƒ½åŠ›
        # æµ‹è¯•é”™è¯¯æ¢å¤æ—¶é—´
```

### è´Ÿè½½æµ‹è¯•
```python
class LoadTestSuite:
    def test_concurrent_recommendations(self):
        """æµ‹è¯•å¹¶å‘æ¨èå¤„ç†èƒ½åŠ›"""
        concurrent_users = [5, 10, 15, 20]
        
        for user_count in concurrent_users:
            with ThreadPoolExecutor(max_workers=user_count) as executor:
                futures = []
                for i in range(user_count):
                    future = executor.submit(self.simulate_user_session)
                    futures.append(future)
                
                success_count = 0
                total_time = 0
                
                for future in as_completed(futures):
                    try:
                        session_time = future.result()
                        success_count += 1
                        total_time += session_time
                    except Exception as e:
                        logger.error(f"Session failed: {e}")
                
                success_rate = success_count / user_count
                avg_response_time = total_time / success_count if success_count > 0 else float('inf')
                
                assert success_rate >= 0.95, f"Success rate {success_rate:.2%} below 95%"
                assert avg_response_time < 3.0, f"Average response time {avg_response_time:.2f}s too high"
```

## ğŸ“Š æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ

### è‡ªåŠ¨åŒ–æµ‹è¯•æŠ¥å‘Š
```python
class TestReportGenerator:
    def generate_comprehensive_report(self, test_results: dict) -> str:
        """ç”Ÿæˆè¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Š"""
        report_sections = {
            'executive_summary': self.create_executive_summary(test_results),
            'recommendation_quality': self.analyze_recommendation_quality(test_results),
            'llm_performance': self.analyze_llm_performance(test_results),
            'system_performance': self.analyze_system_performance(test_results),
            'edge_case_handling': self.analyze_edge_cases(test_results),
            'recommendations': self.generate_improvement_recommendations(test_results)
        }
        
        return self.format_html_report(report_sections)
    
    def create_quality_dashboard(self, test_results: dict) -> dict:
        """åˆ›å»ºè´¨é‡æŒ‡æ ‡ä»ªè¡¨æ¿"""
        dashboard_metrics = {
            'overall_score': self.calculate_overall_quality_score(test_results),
            'allergen_safety_rate': test_results['allergen_safety']['success_rate'],
            'nutrition_improvement_rate': test_results['nutrition']['improvement_rate'],
            'response_time_p95': test_results['performance']['response_time_p95'],
            'llm_quality_score': test_results['llm']['quality_score'],
            'edge_case_success_rate': test_results['edge_cases']['success_rate']
        }
        
        return dashboard_metrics
```

## ğŸ¯ æµ‹è¯•æˆåŠŸæ ‡å‡†

### åŠŸèƒ½æµ‹è¯•æ ‡å‡†
- **è¿‡æ•åŸå®‰å…¨æ€§**: 100%å‡†ç¡®ç‡ï¼Œé›¶å®¹å¿
- **è¥å…»æ”¹å–„ç‡**: >80%çš„æ¨èå•†å“è¥å…»æŒ‡æ ‡ä¼˜äºåŸå•†å“
- **åˆ†ç±»çº¦æŸéµå®ˆ**: æ¡å½¢ç æ‰«æ100%åŒåˆ†ç±»ï¼Œå°ç¥¨åˆ†æåˆç†æ€§>90%
- **æ¨èå¤šæ ·æ€§**: å“ç‰Œè¦†ç›–åº¦>70%ï¼Œä»·æ ¼èŒƒå›´åˆç†

### æ€§èƒ½æµ‹è¯•æ ‡å‡†
- **å“åº”æ—¶é—´**: 95%çš„è¯·æ±‚<2ç§’ï¼Œ99%çš„è¯·æ±‚<3ç§’
- **æ•°æ®åº“æŸ¥è¯¢**: å•æ¬¡æŸ¥è¯¢<100msï¼Œå¤æ‚æŸ¥è¯¢<200ms
- **å¹¶å‘å¤„ç†**: æ”¯æŒ20ä¸ªå¹¶å‘ç”¨æˆ·ï¼ŒæˆåŠŸç‡>95%
- **LLMè°ƒç”¨**: APIæˆåŠŸç‡>99%ï¼Œå¹³å‡å“åº”æ—¶é—´<5ç§’

### LLMè´¨é‡æ ‡å‡†
- **æ•°æ®å‡†ç¡®æ€§**: è¥å…»æ•°æ®å¼•ç”¨å‡†ç¡®ç‡>95%
- **ä¸ªæ€§åŒ–ç¨‹åº¦**: ç”¨æˆ·ç‰¹å¾æåŠç‡>80%
- **å®‰å…¨åˆè§„**: 100%åŒ…å«é€‚å½“çš„åŒ»ç–—å…è´£å£°æ˜
- **å¯æ“ä½œæ€§**: å…·ä½“å»ºè®®æ¯”ä¾‹>70%

## ğŸ“‹ å®æ–½æ­¥éª¤æ¸…å•

### Phase 1: æµ‹è¯•æ¡†æ¶æ­å»º
- [ ] åˆ›å»ºæµ‹è¯•é¡¹ç›®ç»“æ„å’Œé…ç½®
- [ ] å®ç°æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨
- [ ] å¼€å‘æ¨¡æ‹ŸæœåŠ¡å’Œå·¥å…·ç±»
- [ ] å»ºç«‹CI/CDæµ‹è¯•æµæ°´çº¿

### Phase 2: å•å…ƒå’Œé›†æˆæµ‹è¯•
- [ ] ç¼–å†™æ•°æ®åº“æ“ä½œå•å…ƒæµ‹è¯•
- [ ] å®ç°æ¨èç®—æ³•ç»„ä»¶æµ‹è¯•
- [ ] å¼€å‘LLMé›†æˆæµ‹è¯•å¥—ä»¶
- [ ] åˆ›å»ºAPIç«¯ç‚¹é›†æˆæµ‹è¯•

### Phase 3: åœºæ™¯å’ŒåŠŸèƒ½æµ‹è¯•
- [ ] å®ç°æ¡å½¢ç æ‰«æåœºæ™¯æµ‹è¯•
- [ ] å¼€å‘å°ç¥¨åˆ†æåœºæ™¯æµ‹è¯•
- [ ] åˆ›å»ºè¾¹ç•Œæƒ…å†µå’Œå¼‚å¸¸æµ‹è¯•
- [ ] æ„å»ºç”¨æˆ·ä½“éªŒæµ‹è¯•å¥—ä»¶

### Phase 4: æ€§èƒ½å’Œè´Ÿè½½æµ‹è¯•
- [ ] å®ç°å“åº”æ—¶é—´åŸºå‡†æµ‹è¯•
- [ ] å¼€å‘æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½æµ‹è¯•
- [ ] åˆ›å»ºå¹¶å‘è´Ÿè½½æµ‹è¯•å¥—ä»¶
- [ ] å»ºç«‹æ€§èƒ½ç›‘æ§å’Œå‘Šè­¦

### Phase 5: è´¨é‡éªŒè¯å’ŒæŠ¥å‘Š
- [ ] å®ç°æ¨èè´¨é‡éªŒè¯å™¨
- [ ] å¼€å‘LLMè¾“å‡ºè´¨é‡æ£€æŸ¥
- [ ] åˆ›å»ºè‡ªåŠ¨åŒ–æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ
- [ ] å»ºç«‹æŒç»­è´¨é‡ç›‘æ§ç³»ç»Ÿ

### Phase 6: æµ‹è¯•ä¼˜åŒ–å’Œç»´æŠ¤
- [ ] ä¼˜åŒ–æµ‹è¯•æ‰§è¡Œæ•ˆç‡
- [ ] æ‰©å±•æµ‹è¯•è¦†ç›–èŒƒå›´
- [ ] å»ºç«‹æµ‹è¯•æ•°æ®ç®¡ç†
- [ ] åˆ›å»ºæµ‹è¯•æ–‡æ¡£å’ŒåŸ¹è®­ææ–™

## ğŸ”§ Javaå…¼å®¹æ€§æµ‹è¯•å·¥å…·

### Javaå…¼å®¹æ€§éªŒè¯å·¥å…·ç±»
```python
class JavaCompatibilityUtils:
    """Javaå…¼å®¹æ€§æµ‹è¯•å·¥å…·ç±»"""
    
    @staticmethod
    def validate_camel_case_conversion(python_dict: Dict, expected_java_fields: List[str]) -> bool:
        """éªŒè¯Pythonå­—å…¸åˆ°Javaé©¼å³°å‘½åçš„è½¬æ¢"""
        converted = JavaCompatibilityUtils.to_camel_case_dict(python_dict)
        return all(field in converted for field in expected_java_fields)
    
    @staticmethod
    def to_camel_case_dict(snake_dict: Dict) -> Dict:
        """å°†ä¸‹åˆ’çº¿å‘½åè½¬æ¢ä¸ºé©¼å³°å‘½å"""
        camel_dict = {}
        for snake_key, value in snake_dict.items():
            camel_key = JavaCompatibilityUtils.snake_to_camel(snake_key)
            camel_dict[camel_key] = value
        return camel_dict
    
    @staticmethod
    def snake_to_camel(snake_str: str) -> str:
        """ä¸‹åˆ’çº¿è½¬é©¼å³°"""
        components = snake_str.split('_')
        return components[0] + ''.join(x.capitalize() for x in components[1:])
    
    @staticmethod
    def validate_spring_boot_error_format(error_response: Dict) -> bool:
        """éªŒè¯é”™è¯¯å“åº”æ ¼å¼ç¬¦åˆSpring Bootæ ‡å‡†"""
        required_fields = ["success", "message", "error", "timestamp"]
        return all(field in error_response for field in required_fields)
    
    @staticmethod
    def validate_iso_datetime_format(datetime_str: str) -> bool:
        """éªŒè¯æ—¥æœŸæ—¶é—´æ ¼å¼ç¬¦åˆISOæ ‡å‡†"""
        try:
            from datetime import datetime
            datetime.fromisoformat(datetime_str.replace('Z', '+00:00'))
            return True
        except ValueError:
            return False
    
    @staticmethod
    def create_java_compatible_test_data() -> Dict:
        """åˆ›å»ºJavaå…¼å®¹çš„æµ‹è¯•æ•°æ®"""
        return {
            "productData": {
                "barcode": "1234567890123",
                "name": "Test Product",
                "brand": "Test Brand",
                "category": "Food",
                "energyKcalPer100g": 250.5,
                "proteinsPer100g": 15.2,
                "fatPer100g": 8.1,
                "carbohydratesPer100g": 30.5
            },
            "userData": {
                "userId": 1,
                "username": "testUser",
                "email": "test@example.com",
                "age": 25,
                "gender": "male",
                "heightCm": 175,
                "weightKg": 70.5,
                "nutritionGoal": "lose_weight",
                "activityLevel": "moderate"
            },
            "requestData": {
                "scanType": "barcode",
                "userId": 1,
                "productBarcode": "1234567890123",
                "scanContext": {
                    "location": "Tesco",
                    "timestamp": "2025-06-12T14:30:00Z"
                }
            }
        }

class ApiContractValidator:
    """APIå¥‘çº¦éªŒè¯å™¨"""
    
    def __init__(self):
        self.java_field_mappings = {
            # Pythonå­—æ®µå -> Javaå­—æ®µå
            "user_id": "userId",
            "product_barcode": "productBarcode", 
            "scan_type": "scanType",
            "energy_kcal_100g": "energyKcalPer100g",
            "proteins_100g": "proteinsPer100g",
            "recommendation_id": "recommendationId",
            "created_at": "createdAt",
            "updated_at": "updatedAt"
        }
    
    def validate_request_contract(self, request_data: Dict, expected_schema: Dict) -> Dict:
        """éªŒè¯è¯·æ±‚å¥‘çº¦"""
        validation_result = {
            "valid": True,
            "errors": [],
            "warnings": []
        }
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        for required_field in expected_schema.get("required", []):
            if required_field not in request_data:
                validation_result["errors"].append(f"Missing required field: {required_field}")
                validation_result["valid"] = False
        
        # æ£€æŸ¥å­—æ®µç±»å‹
        for field_name, field_value in request_data.items():
            expected_type = expected_schema.get("properties", {}).get(field_name, {}).get("type")
            if expected_type and not self._validate_type(field_value, expected_type):
                validation_result["errors"].append(f"Field {field_name} has invalid type")
                validation_result["valid"] = False
        
        return validation_result
    
    def validate_response_contract(self, response_data: Dict, expected_schema: Dict) -> Dict:
        """éªŒè¯å“åº”å¥‘çº¦"""
        validation_result = {
            "valid": True,
            "errors": [],
            "java_compatibility_score": 0.0
        }
        
        # æ£€æŸ¥Javaå…¼å®¹æ€§
        java_compatible_fields = 0
        total_fields = len(response_data)
        
        for python_field, java_field in self.java_field_mappings.items():
            if python_field in str(response_data).lower():
                # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†Javaé£æ ¼çš„å­—æ®µå
                if java_field in response_data:
                    java_compatible_fields += 1
                else:
                    validation_result["warnings"].append(f"Field {python_field} should use Java naming: {java_field}")
        
        if total_fields > 0:
            validation_result["java_compatibility_score"] = java_compatible_fields / total_fields
        
        return validation_result
    
    def _validate_type(self, value, expected_type: str) -> bool:
        """éªŒè¯æ•°æ®ç±»å‹"""
        type_validators = {
            "string": lambda x: isinstance(x, str),
            "integer": lambda x: isinstance(x, int),
            "number": lambda x: isinstance(x, (int, float)),
            "boolean": lambda x: isinstance(x, bool),
            "array": lambda x: isinstance(x, list),
            "object": lambda x: isinstance(x, dict)
        }
        
        validator = type_validators.get(expected_type.lower())
## ğŸ”§ æµ‹è¯•å·¥å…·å’Œä¾èµ–ï¼ˆJavaå…¼å®¹æ€§å¢å¼ºï¼‰

### æ ¸å¿ƒæµ‹è¯•åº“
```python
# requirements_test.txt
pytest>=7.0.0              # æµ‹è¯•æ¡†æ¶
pytest-asyncio>=0.21.0     # å¼‚æ­¥æµ‹è¯•æ”¯æŒ
pytest-mock>=3.10.0        # Mockå¯¹è±¡
pytest-cov>=4.0.0          # ä»£ç è¦†ç›–ç‡
pytest-xdist>=3.2.0        # å¹¶è¡Œæµ‹è¯•æ‰§è¡Œ
pytest-html>=3.1.0         # HTMLæµ‹è¯•æŠ¥å‘Š

# Javaå…¼å®¹æ€§æµ‹è¯•ä¸“ç”¨
pydantic>=1.10.0           # æ•°æ®éªŒè¯å’Œåºåˆ—åŒ–
jsonschema>=4.17.0         # JSON schemaéªŒè¯
requests>=2.28.0           # HTTPå®¢æˆ·ç«¯æµ‹è¯•
responses>=0.22.0          # HTTPå“åº”Mock

# æ•°æ®åº“æµ‹è¯•
sqlalchemy>=1.4.0          # æ•°æ®åº“ORM
pyodbc>=4.0.0              # SQL Serveré©±åŠ¨ï¼ˆé¢„ç•™ï¼‰
pytest-postgresql>=4.1.0   # PostgreSQLæµ‹è¯•æ”¯æŒï¼ˆå¤‡é€‰ï¼‰

# æ€§èƒ½æµ‹è¯•
locust>=2.14.0              # è´Ÿè½½æµ‹è¯•
memory-profiler>=0.60.0     # å†…å­˜æ€§èƒ½åˆ†æ
line-profiler>=4.0.0        # ä»£ç æ€§èƒ½åˆ†æ

# æ•°æ®ç”Ÿæˆå’ŒéªŒè¯
faker>=18.4.0               # æµ‹è¯•æ•°æ®ç”Ÿæˆ
hypothesis>=6.70.0          # å±æ€§æµ‹è¯•
factory-boy>=3.2.0          # æµ‹è¯•å¯¹è±¡å·¥å‚
```

### Javaå…¼å®¹æ€§æµ‹è¯•é…ç½®
```python
# test_config_java_compatibility.py
JAVA_COMPATIBILITY_CONFIG = {
    "field_naming": {
        "style": "camelCase",
        "validation": True,
        "mapping_file": "tests/test_data/java_field_mappings.json"
    },
    "date_time": {
        "format": "ISO_8601",
        "timezone_handling": "UTC",
        "precision": "milliseconds"
    },
    "api_contracts": {
        "request_validation": True,
        "response_validation": True,
        "schema_directory": "tests/test_data/api_schemas/",
        "java_dto_samples": "tests/test_data/java_dto_samples/"
    },
    "database": {
        "test_migration": True,
        "constraint_validation": True,
        "data_type_mapping": True,
        "performance_comparison": True
    },
    "error_handling": {
        "spring_boot_format": True,
        "status_code_mapping": True,
        "exception_structure": True
    }
}
```
```

### æµ‹è¯•ç¯å¢ƒé…ç½®
```python
# test_config.py
TEST_CONFIG = {
    "database": {
        "path": "tests/test_data/test_grocery_guardian.db",
        "reset_on_start": True,
        "populate_test_data": True
    },
    "llm": {
        "use_mock": True,           # ä½¿ç”¨Mock LLMé¿å…APIè´¹ç”¨
        "mock_response_delay": 0.5, # æ¨¡æ‹ŸAPIå»¶è¿Ÿ
        "enable_real_api_tests": False  # ä»…åœ¨å¿…è¦æ—¶å¯ç”¨çœŸå®APIæµ‹è¯•
    },
    "performance": {
        "response_time_targets": {
            "simple_recommendation": 1.0,
            "complex_analysis": 2.0,
            "receipt_processing": 3.0
        },
        "load_test_users": 20,
        "load_test_duration": 60  # ç§’
    }
}
```

è¿™ä¸ªå…¨é¢çš„æµ‹è¯•æ¡†æ¶å°†ç¡®ä¿Grocery Guardianæ¨èç³»ç»Ÿçš„è´¨é‡ã€æ€§èƒ½å’Œå¯é æ€§ï¼Œä¸ºåç»­çš„ç”Ÿäº§éƒ¨ç½²å¥ å®šåšå®çš„åŸºç¡€ã€‚